{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMy6cV7PEVdfEPOr6YPUxNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SY-256/llms-from-scratch/blob/main/notebooks/ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 分類のためのファインチューニング\n",
        "- LLMのさまざまなファインチューニングアプローチ\n",
        "- スパムメールを識別するために事前学習済みLLMをファインチューニングする"
      ],
      "metadata": {
        "id": "uB3dcSbgAbh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 ファインチューニングのさまざまなカテゴリ\n",
        "- インストラクションチューニング: 特定の指示を使用した一連のタスクを言語モデルに訓練することで、自然言語のプロンプトで表示されたタスクを理解して実行する能力を向上させる\n",
        "- 分類チューニング: 特定のクラスラベルを認識する能力を向上させる\n",
        "\n",
        "インストラクションチューニングを行ったモデルは、幅広いタスクに対応できる\n",
        "\n",
        "分類チューニングを行ったモデルは、訓練中に遭遇したクラスの予測に限定される（専門性が高い）"
      ],
      "metadata": {
        "id": "FPEiAu_eAu50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 データセットを準備する"
      ],
      "metadata": {
        "id": "PkrYIKWFHeCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットのダウンロードと解凍\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction\")\n",
        "        return\n",
        "\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        # ファイルダウンロード\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        # ファイル解凍\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path) # ファイル拡張子.tsvを追加\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "id": "Ub2nBQ8xHwru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "m69lWCwHJNDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# クラスラベルの分布\n",
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "id": "DByuo6a3JfLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# アンダーサンプリングして均衡なデータセットを作成\n",
        "def create_balanced_dataset(df):\n",
        "    # スパムの数に合わせてデータセットをアンダーサンプリング\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        "        num_spam, random_state=123\n",
        "    )\n",
        "    balanced_df = pd.concat(\n",
        "        [ham_subset, df[df[\"Label\"] == \"spam\"]]\n",
        "    )\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "id": "3LdMNo9yJoIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルのマッピング\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "ifq4frnRKeO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットを訓練／検証／評価用に分割する\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        "    df = df.sample(\n",
        "        frac=1, random_state=123\n",
        "    ).reset_index(drop=True)\n",
        "    train_end = int(len(df) * train_frac) # 分割インデックスを計算\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    train_df = df[:train_end] # DataFrameを分割\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "5tp1AXyeKp6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVファイルで保存\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "Q5Tv6_AULjm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 データローダーを作成する"
      ],
      "metadata": {
        "id": "vk0cS5JsLzXj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0FotJu1L8Fa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}